<h1 align='center'> :microscope: Credit Card Default Prediction.<h1>

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)

## This repository contains the code and dataset for predicting credit card defaulters. The project uses a dataset containing past credit card users behaviour and information

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)

## ðŸ“‹ Abstract

<p>This project is aimed at predicting the case of customers default payments in Taiwan. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. We can use the K-S chart to evaluate which customers will default on their credit card payments

</p>

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)

##  ðŸ’¾ Project Files Description

<p>This Project includes :-
  <li>Google Colab NoteBook</li>
  <li>Project Summary (with the GitHub Repo link inside)</li>
  <li>Presentation Video</li>
</p>



### Output:
- [Google Colab](https://colab.research.google.com/drive/1jdba0-hesS1Jpsph_vnkhSrypbIjyBub?usp=sharing) - All the outputs are visible in the provided colab notebook.



## ðŸ—º Roadmap and Navigation guide

<hr>

### Step 1: Data Collection
Collect the historical stock prices of Yes Bank from January 2005 to September 2020. Include variables such as opening price, highest price, lowest price, and closing price and date

<hr>

### Step 2: Data Cleaning and Preprocessing
Clean the dataset by removing any missing values, outliers, or errors. Preprocess the dataset by scaling or normalizing the features as necessary.

<hr>

### Step 3: Model Building
Divide the dataset into training and testing sets. Implement Multiple classification  models to predict the credit card defaulter. Tune the models by adjusting the hyperparameters to optimize performance.

<hr>

### Step 4: Model Evaluation
Evaluate the models' performance using Recall and Precision. Compare the performance of the models to determine which one performs better.

<hr>

### Step 5: Results and Conclusion
Present the results of the classification. Discuss the implications of the results and their potential impact on investors. Provide conclusions and suggestions for future research.

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)

## ðŸ›  Builds with

![Python](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue)

![NumPy](https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white)

![Pandas](https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white)

![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)

![Seaborn](https://img.shields.io/badge/Seaborn-blue?style=for-the-badge&logo=Seaborn)

![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)

![SciPy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=for-the-badge&logo=scipy&logoColor=%white)

![Plotly](https://img.shields.io/badge/Plotly-%233F4F75.svg?style=for-the-badge&logo=plotly&logoColor=white)

![GoogleColab](https://img.shields.io/badge/GoogleColab-orange?style=for-the-badge&logo=GoogleColab)

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)

## :scroll: Conclusion

We have seen that our dataset was imbalanced class.

Most of the credit card holder was Female and Male customers have high default ratio.

Higher educated persons have less rate to be default whereas lower educated will maximum chances to be default.

After age 60s years chance of default is high.

The important metric to compare all the algorithms in this case is â€˜Recallâ€™. As the company canâ€™t afford to predict False negative i.e. predict defaulter as a non defaulter. Since, company is one, who will give to money to the customers,if, for any reason giving money to defaulter is gaining more risk to getting the investment back. Hence, here identifying false negative is important.

K-Nearest Neighbors model with hyperparameter tunning perform well in terms of recall(92%).

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)

## ðŸ’¶ Credits

Reach-out to me in following spaces.

[![GitHub](https://img.shields.io/badge/my_portfolio-000?style=for-the-badge&logo=ko-fi&logoColor=white)](https://github.com/Vrushali065)

[![Email](https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:vrushaliphalke99@gmail.com?subject=Hi "Hi!")

[![LinkedIn](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/vrushali-phalke-075427247/)

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)

## ðŸ“š References

*	Python documentation
*	Pandas documentation
*	Seaborn documentation
* Scikit-Learn documentation
*	Towards data science
* Analytics Vidya
*	StackoverFlow
*	wikipedia
*	Google data analytics professional.

![--------------------------------------------------------------------------------------------](https://github.com/andreasbm/readme/blob/master/assets/lines/grass.png)
